{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# Important! Uncomment this line to set your own API key\n",
    "# os.environ[\"OPEN_AI_KEY\"] = \"sk-...\"\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Python in 10 minutes\n",
    "\n",
    "This interface allows you to run Python code interactively and view the results immediately, along with any visualizations or text explanations. Each block of code or text you see is contained in what we call a \"cell.\"\n",
    "\n",
    "## Basic Operations\n",
    "\n",
    "- **Running a Cell**: You can run the code or render the markdown in a cell by selecting it and pressing `Shift + Enter`, or by clicking the \"Run\" button in the toolbar.\n",
    "- **Adding New Cells**: Add a new cell by clicking the \"+\" button in the toolbar.\n",
    "- **Cell Types**: Cells can be code cells or markdown cells. Switch the type using the dropdown in the toolbar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Python Example\n",
    "\n",
    "# Printing a message\n",
    "print(\"Hello, World!\")\n",
    "\n",
    "# Basic arithmetic\n",
    "result = 7 * 6\n",
    "print(\"7 multiplied by 6 is\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Variables\n",
    "\n",
    "# Store a value in a variable\n",
    "a = 10\n",
    "\n",
    "# Use the variable in a calculation\n",
    "b = a * 2\n",
    "\n",
    "# Print the result\n",
    "print(\"The result of a multiplied by 2 is\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Structures\n",
    "\n",
    "# List: an ordered collection of items\n",
    "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
    "print(\"Fruits List:\", fruits)\n",
    "\n",
    "# Dictionary: key-value pairs\n",
    "prices = {\"apple\": 0.40, \"banana\": 0.50, \"cherry\": 0.30}\n",
    "print(\"Fruit Prices:\", prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through a list\n",
    "for fruit in fruits:\n",
    "    print(fruit, \"costs\", prices[fruit], \"each\")\n",
    "\n",
    "# Conditional: if statement\n",
    "if \"banana\" in fruits:\n",
    "    print(\"Yes, we have bananas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Functions\n",
    "\n",
    "Functions are a way to organize your code into blocks that can be called multiple times throughout your program. They allow you to write cleaner, more modular code and make your scripts easier to maintain and debug. Functions in Python are defined using the `def` keyword.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Simple Function\n",
    "\n",
    "\n",
    "def greet(name):\n",
    "    \"\"\"This function greets the person whose name is passed as a parameter\"\"\"\n",
    "    return f\"Hello, {name}! Welcome to our notebook.\"\n",
    "\n",
    "\n",
    "# Calling the function\n",
    "greeting = greet(\"Alice\")\n",
    "print(greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function with Parameters and Return Value\n",
    "\n",
    "\n",
    "def calculate_area(length, width):\n",
    "    \"\"\"This function returns the area of a rectangle given its length and width.\"\"\"\n",
    "    area = length * width\n",
    "    return area\n",
    "\n",
    "\n",
    "# Using the function\n",
    "rect_area = calculate_area(10, 5)\n",
    "print(\"The area of the rectangle is:\", rect_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add a variable to a string by using format\n",
    "\n",
    "name = \"Lebron James\"\n",
    "\n",
    "template = \"\"\"{name} is from Ohio\"\"\"\n",
    "\n",
    "print(\"Without calling format:\", template)\n",
    "print(\"After calling format:\", template.format(name=name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started with the case study!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Architecture\n",
    "\n",
    "The architecture of the system is as follows:\n",
    "\n",
    "1. We chunk up the document into distinct “sections” and embed those sections\n",
    "2. Then, we embed the user query and find the most similar part of the document.\n",
    "3. We feed the original question along with context we found to the LLM and receive an answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What exactly is an embedding?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, NOT_GIVEN\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#########################\n",
    "### UTILITY FUNCTIONS ###\n",
    "#########################\n",
    "\n",
    "# instantiating the OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPEN_AI_KEY\"))\n",
    "batch_size = 250\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "\n",
    "\n",
    "# wrapper function around openai to directly return embedding of text\n",
    "def get_embedding(text: str | list[str], dimensions: int = NOT_GIVEN) -> list[float]:\n",
    "    \"\"\"Get the embedding of the input text.\"\"\"\n",
    "    if dimensions:\n",
    "        assert dimensions <= 256, \"The maximum number of dimensions is 256.\"\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=text, model=embedding_model, dimensions=dimensions\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "def get_many_embeddings(texts: list[str]) -> list[list[float]]:\n",
    "    \"\"\"Get the embeddings of multiple texts.\"\"\"\n",
    "    batch_size = 250\n",
    "    res = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        api_resp = client.embeddings.create(input=batch_texts, model=embedding_model)\n",
    "        batch_res = [val.embedding for val in api_resp.data]\n",
    "        res.extend(batch_res)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# simple utility function to add a vector to a 3D plot\n",
    "def add_vector_to_graph(\n",
    "    fig: go.Figure, vector: list[float], color: str = \"red\", name: Optional[str] = None\n",
    ") -> go.Figure:\n",
    "    # Ensure vector has exactly three components\n",
    "    assert len(vector) == 3, \"Vector must have exactly 3 components to visualize.\"\n",
    "\n",
    "    # Origin point\n",
    "    origin = [0, 0, 0]\n",
    "\n",
    "    # Components of the vector\n",
    "    x_component, y_component, z_component = vector\n",
    "\n",
    "    # Adding the line part of the vector\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[origin[0], x_component],\n",
    "            y=[origin[1], y_component],\n",
    "            z=[origin[2], z_component],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color, width=5),\n",
    "            name=name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding the cone at the tip of the vector\n",
    "    fig.add_trace(\n",
    "        go.Cone(\n",
    "            x=[x_component],\n",
    "            y=[y_component],\n",
    "            z=[z_component],\n",
    "            u=[x_component],\n",
    "            v=[y_component],\n",
    "            w=[z_component],\n",
    "            sizemode=\"scaled\",\n",
    "            sizeref=0.1,\n",
    "            showscale=False,\n",
    "            colorscale=[[0, color], [1, color]],\n",
    "            hoverinfo=\"none\",\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_new_graph() -> go.Figure:\n",
    "    \"\"\"Create a 3D plotly figure with a simple layout.\"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # make sure the plot isn't rotated\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.5, y=1.5, z=0.5),  # Adjust the camera position\n",
    "                up=dict(x=0, y=0, z=1),  # Sets the z-axis as \"up\"\n",
    "                center=dict(x=0, y=0, z=0),  # Focuses the camera on the origin\n",
    "            ),\n",
    "            aspectmode=\"cube\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a dot at the origin\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[0],\n",
    "            y=[0],\n",
    "            z=[0],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=\"black\", symbol=\"circle\"),\n",
    "            name=\"Origin\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get started\n",
    "\n",
    "For the purpose of the notebook we're going to use an OpenAI approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try using the get_embedding function\n",
    "result = get_embedding(\"lead contamination\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of numbers! OpenAI embedding support built in dimensionality reduction - let's try using that and visualizing the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_new_graph()\n",
    "\n",
    "text = \"lead contamination\"\n",
    "\n",
    "# Get the embedding of the text\n",
    "vector = get_embedding(text, dimensions=3)\n",
    "print(f\"Resulting vector: {vector} with {len(vector)} dimensions\")\n",
    "\n",
    "# Add the vector to the plot\n",
    "add_vector_to_graph(graph, vector, name=text)\n",
    "\n",
    "# Show the plot\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try plotting a couple vectors at once to see if we can see any patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_new_graph()\n",
    "\n",
    "text = \"lead contamination\"\n",
    "lead_contamination_vector = get_embedding(text, dimensions=3)\n",
    "add_vector_to_graph(graph, lead_contamination_vector, name=text, color=\"purple\")\n",
    "\n",
    "text = \"asbestos\"\n",
    "asbestos_vector = get_embedding(text, dimensions=3)\n",
    "add_vector_to_graph(graph, asbestos_vector, name=text, color=\"blue\")\n",
    "\n",
    "text = \"judo\"\n",
    "judo_vector = get_embedding(text, dimensions=3)\n",
    "add_vector_to_graph(graph, judo_vector, name=text, color=\"red\")\n",
    "\n",
    "# Show the plot\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we can quantify the similarity between two vectors? One common way is to use the cosine similarity. The cosine similarity between two vectors is the cosine of the angle between them. It ranges from -1 (opposite directions) to 1 (same direction), with 0 indicating orthogonality.\n",
    "\n",
    "*Note:* You can try your own vectors by changing the text variable in the code above. You may see unintuitive results because we're only using 3 dimensions - increasing the dimensions will help (although we won't be able to visualize it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(a: list[float], b: list[float]) -> float:\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "# We can use the cosine similarity to compare the similarity between two vectors\n",
    "similarity = cosine_similarity(lead_contamination_vector, judo_vector)\n",
    "print(f\"The similarity between 'lead contamination' and 'judo' is {similarity:.2f}\")\n",
    "\n",
    "similarity = cosine_similarity(lead_contamination_vector, asbestos_vector)\n",
    "print(f\"The similarity between 'lead contamination' and 'asbestos' is {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parsing Documents\n",
    "\n",
    "Large language models are currently primarly optimized for working with text. As a result when dealing with documents like PDF's we need to first convert them into a text format before we can feed them into the model.\n",
    "\n",
    "We maintain a popular open source library for doing this called [openparse](https://github.com/Filimoa/open-parse/). It is a simple and easy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openparse\n",
    "\n",
    "#########################\n",
    "### UTILITY FUNCTIONS ###\n",
    "#########################\n",
    "\n",
    "\n",
    "class VectorDatabase:\n",
    "    \"\"\"\n",
    "    A simple in-memory database to store nodes along with their vectors and perform similarity search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "\n",
    "    def add_node(self, node: openparse.Node) -> None:\n",
    "        \"\"\"Add a node along with its vector to the database.\"\"\"\n",
    "        assert node.embedding is not None, \"Node must have an embedding.\"\n",
    "\n",
    "        for existing_node in self.nodes:\n",
    "            if existing_node.text == node.text:\n",
    "                print(f\"Node with id {node.node_id} already exists. Skipping\")\n",
    "                return\n",
    "\n",
    "        self.nodes.append(node)\n",
    "\n",
    "    def find_node(self, node_id: str):\n",
    "        \"\"\"Retrieve a node by its ID.\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.node_id == node_id:\n",
    "                return node\n",
    "        return None\n",
    "\n",
    "    def find_similar_node(\n",
    "        self, input_vector: list[float], top_k: int = 3\n",
    "    ) -> list[openparse.Node]:\n",
    "        \"\"\"Find the top_k nodes with the highest cosine similarity to the input_vector.\"\"\"\n",
    "        assert self.nodes, \"Database is empty. Please add nodes first.\"\n",
    "        assert top_k <= len(self.nodes), (\n",
    "            \"top_k should be less than or equal to the number of nodes.\"\n",
    "        )\n",
    "\n",
    "        similarities = []\n",
    "        for node in self.nodes:\n",
    "            similarity = cosine_similarity(input_vector, node.embedding)\n",
    "            similarities.append((node, similarity))\n",
    "\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return [node for node, _ in similarities[:top_k]]\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        \"\"\"Return the number of nodes in the database.\"\"\"\n",
    "        return len(self.nodes)\n",
    "\n",
    "    def delete_all_nodes(self) -> None:\n",
    "        \"\"\"Delete all nodes from the database.\"\"\"\n",
    "        self.nodes = []\n",
    "\n",
    "\n",
    "db = VectorDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openparse\n",
    "\n",
    "doc_path = \"./docs/portland-site-assessment-phase-1.pdf\"\n",
    "pdf = openparse.Pdf(doc_path)\n",
    "parser = openparse.DocumentParser()\n",
    "parsed_doc = parser.parse(doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try looking at the first couple nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in parsed_doc.nodes[10:11]:\n",
    "    display(node)\n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's embed all the nodes and add to the database.\n",
    "\n",
    "<img src=\"https://sergey-filimonov.nyc3.cdn.digitaloceanspaces.com/misc/misc-data-or-images-for-notebooks/parsing-v2.png\" alt=\"Parsing Overview\" style=\"width: 80%; height: auto; display: block; margin-left: auto; margin-right: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's embed all the nodes and add to the database\n",
    "raw_node_texts = [node.text for node in parsed_doc.nodes]\n",
    "embeddings = get_many_embeddings(raw_node_texts)\n",
    "\n",
    "for node, embedding in zip(parsed_doc.nodes, embeddings):\n",
    "    node.embedding = embedding\n",
    "    db.add_node(node)\n",
    "\n",
    "print(\"=== Database now has \", db.num_nodes, \" nodes ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### UTILITY FUNCTIONS ###\n",
    "#########################\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def get_completion(prompt: str) -> Markdown:\n",
    "    \"\"\"\n",
    "    OpenAI returns a complex object, this is a simple wrapper function to directly return the completion text.\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    cost_per_million_tokens = 4.00\n",
    "    cost_dollars = completion.usage.total_tokens / 1_000_000 * cost_per_million_tokens\n",
    "\n",
    "    print(\n",
    "        f\"Completion used {completion.usage.total_tokens} tokens costing ${cost_dollars:.2f}\"\n",
    "    )\n",
    "\n",
    "    return Markdown(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "def display_similar_nodes(\n",
    "    similar_nodes: list[openparse.Node], query_vector: list[float], pdf: openparse.Pdf\n",
    ") -> None:\n",
    "    page_nums = set()\n",
    "    annotations = []\n",
    "    for node in similar_nodes:\n",
    "        sim = cosine_similarity(query_vector, node.embedding)\n",
    "        page_nums.add(node.start_page)\n",
    "        page_nums.add(node.end_page)\n",
    "        annotations.append(round(sim, 3))\n",
    "\n",
    "    pdf.display_with_bboxes(similar_nodes, page_nums=page_nums, annotations=annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try asking one of our original questions\n",
    "\n",
    "question = \"Is there lead contamination into the groundwater?\"\n",
    "\n",
    "# Get the embedding of the text\n",
    "query_vector = get_embedding(question)\n",
    "\n",
    "# find the most similar node\n",
    "similar_nodes = db.find_similar_node(query_vector, top_k=5)\n",
    "\n",
    "for node in similar_nodes:\n",
    "    sim = cosine_similarity(query_vector, node.embedding)\n",
    "    print(\n",
    "        f\"Found similar node on page {node.start_page} with a similarity of {sim:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single string of all the similar nodes\n",
    "context = \"\\n\\n\".join([node.text for node in similar_nodes])\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok let's try running a completion\n",
    "\n",
    "To reiterate, we first query the document for the most relevant information using the vector search. Then we feed the question and the context into the LLM to get an answer.\n",
    "\n",
    "<img src=\"https://sergey-filimonov.nyc3.cdn.digitaloceanspaces.com/misc/misc-data-or-images-for-notebooks/eca-docs-rag-overview-v2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Using the document provided, answer the following question:\n",
    "\n",
    "question: {question}\n",
    "\n",
    "context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "completion = get_completion(prompt)\n",
    "\n",
    "print(\"Original Question:\", question)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can display citations showing users exactly where we got our answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similar_nodes(similar_nodes, query_vector, pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class ContainsHazards(BaseModel):\n",
    "    has_lead: bool\n",
    "\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    response_format=ContainsHazards,\n",
    ")\n",
    "\n",
    "response = response.choices[0].message.parsed\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Prompting\n",
    "\n",
    "We can use the output of the model to drill into a more specific question. So in our case we found there was lead contamination, so we can ask a more specific question about the mitigations performed.\n",
    "\n",
    "<img src=\"https://sergey-filimonov.nyc3.cdn.digitaloceanspaces.com/misc/misc-data-or-images-for-notebooks/structured-outputs-overview-v2.png\" alt=\"Structured Outputs Overview\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.has_lead:\n",
    "    question = \"What mitigations have been performed up to this point to deal with the lead exposure?\"\n",
    "\n",
    "    query_vector = get_embedding(question)\n",
    "\n",
    "    similar_nodes = db.find_similar_node(query_vector, top_k=5)\n",
    "\n",
    "    context = \"\\n\\n\".join([node.text for node in similar_nodes])\n",
    "\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "    mitigations_performed = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitigations_performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = (\n",
    "    \"Why were the following mitigations to remove the lead from the property ineffective \"\n",
    "    + mitigations_performed.data\n",
    ")\n",
    "\n",
    "query_vector = get_embedding(question)\n",
    "\n",
    "# this is a more complex question, let's expand the search to top 9 nodes\n",
    "similar_nodes = db.find_similar_node(query_vector, top_k=9)\n",
    "\n",
    "context = \"\\n\\n\".join([node.text for node in similar_nodes])\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "failure_reasons = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Limitations to RAG\n",
    "\n",
    "There's many classes of queries that can be challenging to answer with the architecture we've outlined thus far. \n",
    "\n",
    "1.\tTemporal Reasoning: Answering time-specific questions, such as \"what happened last quarter?\" can be challenging because embeddings are designed to represent the general meaning of a phrase. They don’t inherently account for when events occurred. Without explicit mechanisms to distinguish between recent and older data, our RAG system cannot reliably retrieve time-sensitive responses.\n",
    "\n",
    "2.\tConditional Reasoning: Queries with \"if-then\" logic present additional complexity. For instance, \"If claim volume rose, what actions were taken?\" requires the system to evaluate an initial condition (changes in claim volume) before retrieving data related to that condition. \n",
    "\n",
    "3.\tCompound Queries: Actuarial analysis often requires decomposing complex questions into manageable parts, such as “Identify high-risk claims and summarize major patterns”, Since terms like “high-risk” may not explicitly appear in the data, this type of query requires a preprocessing step to define what constitutes a high-risk claim, such as specific claim attributes or risk factors.\n",
    "\n",
    "Increasing the context windows of LLMs can brute force some of these limitations, but it also means that we can't use the same approach for longer documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Challenges (Optional)\n",
    "\n",
    "#### 1. Let's pass the entire document to ChatGPT and see if we get a different answer\n",
    "\n",
    "In our example our document is short enough that we can pass the entire document to ChatGPT. This is very powerful, but it also means that we can't use the same approach for longer documents.\n",
    "\n",
    "Once again if you're having trouble, you can find the full solution in the `./solutions.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try combining all the nodes into one string,\n",
    "# Hint: You can iterate across the original document nodes by using `for node in parsed_doc.nodes:`. Each Node has a `node.text` attribute!\n",
    "\n",
    "# Create a prompt the same way we created one earlier except now pass the full document string\n",
    "\n",
    "# Request a completion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
